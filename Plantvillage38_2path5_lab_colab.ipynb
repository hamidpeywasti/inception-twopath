{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7370060,
          "sourceType": "datasetVersion",
          "datasetId": 4281973
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidpeywasti/inception-twopath/blob/main/Plantvillage38_2path5_lab_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monitor='val_accuracy'\n",
        "epochs=150\n",
        "batch_size=32\n",
        "input_shape=(224, 224, 3) # please resize it to (224,224,3) if you have enough RAM\n",
        "Verbose=True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:06:16.367222Z",
          "iopub.execute_input": "2024-01-20T11:06:16.367968Z",
          "iopub.status.idle": "2024-01-20T11:06:16.372389Z",
          "shell.execute_reply.started": "2024-01-20T11:06:16.367935Z",
          "shell.execute_reply": "2024-01-20T11:06:16.371347Z"
        },
        "trusted": true,
        "id": "2b9pfZKVJYdv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"Python version:\", sys.version)\n",
        "\n",
        "import skimage\n",
        "print('skimage:',  skimage.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow:',tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:09:24.631659Z",
          "iopub.execute_input": "2024-01-20T11:09:24.632039Z",
          "iopub.status.idle": "2024-01-20T11:09:24.641071Z",
          "shell.execute_reply.started": "2024-01-20T11:09:24.632009Z",
          "shell.execute_reply": "2024-01-20T11:09:24.640101Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXGEryUVJYdx",
        "outputId": "dc859aec-8e0c-43e6-a685-dcc96a52cb21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "skimage: 0.19.3\n",
            "Tensorflow: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apt-get install git python3-opencv\n",
        "import os\n",
        "\n",
        "if not os.path.isdir('k'):\n",
        "  !git clone https://github.com/hamidpeywasti/keras-neural-api k\n",
        "else:\n",
        "  !cd k && git pull\n",
        "\n",
        "!cd k && pip install .\n",
        "\n",
        "!rm -rf k\n",
        "\n",
        "import cai\n",
        "import cai.datasets\n",
        "import cai.models\n",
        "import cai.inception_v3\n",
        "import cai.layers\n",
        "import cai.util\n",
        "from cai.layers import conv2d_bn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:06:36.144105Z",
          "iopub.execute_input": "2024-01-20T11:06:36.145057Z",
          "iopub.status.idle": "2024-01-20T11:06:55.566291Z",
          "shell.execute_reply.started": "2024-01-20T11:06:36.145025Z",
          "shell.execute_reply": "2024-01-20T11:06:55.565314Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn_xXkOoJYdy",
        "outputId": "87e320ec-1776-4461-ef7e-dd80e332eb76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'k'...\n",
            "remote: Enumerating objects: 1807, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 1807 (delta 135), reused 147 (delta 72), pack-reused 1588\u001b[K\n",
            "Receiving objects: 100% (1807/1807), 15.69 MiB | 22.85 MiB/s, done.\n",
            "Resolving deltas: 100% (1248/1248), done.\n",
            "Processing /content/k\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from cai==0.1.7) (1.5.3)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from cai==0.1.7) (0.19.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.2.30 in /usr/local/lib/python3.10/dist-packages (from cai==0.1.7) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from cai==0.1.7) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cai==0.1.7) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->cai==0.1.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->cai==0.1.7) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.0->cai==0.1.7) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.0->cai==0.1.7) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.22.0->cai==0.1.7) (1.16.0)\n",
            "Building wheels for collected packages: cai\n",
            "  Building wheel for cai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cai: filename=cai-0.1.7-py3-none-any.whl size=61388 sha256=32fbdf179a43517b4f23b40ead7589842a9bf85e52120b42a5848e4e67dccf4d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-58j9hzgq/wheels/80/61/f5/947bedc7e497038def7d1381fb65d37bd126a80e010114b8f1\n",
            "Successfully built cai\n",
            "Installing collected packages: cai\n",
            "Successfully installed cai-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def two_path5_inception_v3(\n",
        "    include_top=True,\n",
        "    weights=None, #'two_paths_plant_leafs'\n",
        "    input_shape=(224,224,3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    two_paths=False,\n",
        "    deep_two_paths=False,\n",
        "    deep_two_paths_compression=0.655,\n",
        "    deep_two_paths_bottleneck_compression=0.5,\n",
        "    l_ratio=0.5,\n",
        "    ab_ratio=0.5,\n",
        "    max_mix_idx=10,\n",
        "    max_mix_deep_two_paths_idx=-1,\n",
        "    model_name='two_path_inception_v3',\n",
        "    kType=0,\n",
        "    **kwargs\n",
        "):\n",
        "    \"\"\"\n",
        "    Instantiates the Inception v3 architecture with 2 paths options.\n",
        "    \"\"\"\n",
        "    img_input = keras.layers.Input(shape=input_shape)\n",
        "    if (deep_two_paths):  max_mix_deep_two_paths_idx = max_mix_idx\n",
        "\n",
        "    if keras.backend.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "\n",
        "\n",
        "    if two_paths:\n",
        "        if (l_ratio>0):\n",
        "            l_branch = cai.layers.CopyChannels(0,1)(img_input)\n",
        "            l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), 3, 3, strides=(2, 2), padding='valid')\n",
        "            l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), 3, 3, padding='valid')\n",
        "            l_branch = conv2d_bn(l_branch, int(round(64*l_ratio)), 3, 3)\n",
        "            l_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(l_branch)\n",
        "\n",
        "            #l_branch    = conv2d_bn(x, int(round(80*deep_two_paths_bottleneck_compression)), 1, 1, padding='valid', name='second_block_ta', activation=None, has_batch_norm=True)\n",
        "            l_branch    = cai.inception_v3.create_inception_path(last_tensor=l_branch, compression=deep_two_paths_bottleneck_compression, channel_axis=channel_axis, name='second_block_ta', activation=None, has_batch_norm=True, kType=kType)\n",
        "            # l_branch    = conv2d_bn(l_branch,    int(round(80 *deep_two_paths_compression)), 1, 1, padding='valid')\n",
        "            l_branch = cai.inception_v3.kInceptionPointwise(l_branch, filters=int(round(80 *l_ratio)), name='l_branch_path', kType=kType)\n",
        "            l_branch    = conv2d_bn(l_branch,    int(round(192*l_ratio)), 3, 3, padding='valid')\n",
        "\n",
        "        if (ab_ratio>0):\n",
        "            ab_branch = cai.layers.CopyChannels(1,2)(img_input)\n",
        "            ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), 3, 3, strides=(2, 2), padding='valid')\n",
        "            ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), 3, 3, padding='valid')\n",
        "            ab_branch = conv2d_bn(ab_branch, int(round(64*ab_ratio)), 3, 3)\n",
        "            ab_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(ab_branch)\n",
        "\n",
        "            #ab_branch = conv2d_bn(x, int(round(80*deep_two_paths_bottleneck_compression)), 1, 1, padding='valid', name='second_block_tb', activation=None, has_batch_norm=True)\n",
        "            ab_branch = cai.inception_v3.create_inception_path(last_tensor=ab_branch, compression=deep_two_paths_bottleneck_compression, channel_axis=channel_axis, name='second_block_tb', activation=None, has_batch_norm=True, kType=kType)\n",
        "            # ab_branch = conv2d_bn(ab_branch, int(round(80 *deep_two_paths_compression)), 1, 1, padding='valid')\n",
        "            ab_branch = cai.inception_v3.kInceptionPointwise(ab_branch, filters=int(round(80 *ab_ratio)), name='ab_branch_path', kType=kType)\n",
        "            ab_branch = conv2d_bn(ab_branch, int(round(192*ab_ratio)), 3, 3, padding='valid')\n",
        "\n",
        "        if (l_ratio>0):\n",
        "            if (ab_ratio>0):\n",
        "                x = keras.layers.Concatenate(axis=channel_axis, name='concat_first_block')([l_branch, ab_branch])\n",
        "            else:\n",
        "                x = l_branch\n",
        "        else:\n",
        "            x = ab_branch\n",
        "\n",
        "    else:\n",
        "        single_branch = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
        "        single_branch = conv2d_bn(single_branch, 32, 3, 3, padding='valid')\n",
        "        single_branch = conv2d_bn(single_branch, 64, 3, 3)\n",
        "        single_branch = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(single_branch)\n",
        "\n",
        "        # x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
        "        single_branch= cai.inception_v3.kInceptionPointwise(single_branch, filters=80, name='single_path', kType=kType)\n",
        "        x = conv2d_bn(single_branch, 192, 3, 3, padding='valid')\n",
        "\n",
        "\n",
        "    x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    if max_mix_idx >= 0:\n",
        "        for id_layer in range(max_mix_idx+1):\n",
        "            if (max_mix_deep_two_paths_idx >= id_layer):\n",
        "                x = cai.inception_v3.create_inception_v3_two_path_mixed_layer(x,  id=id_layer,  name='mixed'+str(id_layer),\n",
        "                    channel_axis=channel_axis, bottleneck_compression=deep_two_paths_bottleneck_compression,\n",
        "                    compression=deep_two_paths_compression, has_batch_norm=True, kType=kType)\n",
        "            else:\n",
        "                x = cai.inception_v3.create_inception_v3_mixed_layer(x,  id=id_layer,  name='mixed'+str(id_layer), channel_axis=channel_axis, kType=kType)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    inputs = img_input\n",
        "    # Create model.\n",
        "    model = keras.models.Model(inputs, x, name=model_name)\n",
        "    return model\n",
        "\n",
        "def plot_history(filename):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "    plt.ylim(ymin=0, ymax=1.5)\n",
        "\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    plt.savefig(filename)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:06:55.568433Z",
          "iopub.execute_input": "2024-01-20T11:06:55.568790Z",
          "iopub.status.idle": "2024-01-20T11:06:55.593358Z",
          "shell.execute_reply.started": "2024-01-20T11:06:55.568757Z",
          "shell.execute_reply": "2024-01-20T11:06:55.592468Z"
        },
        "trusted": true,
        "id": "BIUu8zhtJYdy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "-vs30GgrJYd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_zip_file=\"https://data.mendeley.com/datasets/tywbtsjrjv/1/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/Plant_leaf_diseases_dataset_without_augmentation.zip?dl=1\"\n",
        "local_zip_file=\"plant_leaf.zip\"\n",
        "expected_folder_name=\"plant_leaf\"\n",
        "Verbose=True\n",
        "cai.datasets.download_zip_and_extract(\n",
        "    url_zip_file=url_zip_file, local_zip_file=local_zip_file,\n",
        "    expected_folder_name=expected_folder_name, Verbose=Verbose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx0ONrKKKo8Q",
        "outputId": "c2e75911-6b12-4838-ada0-36f28e0d2d43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading:  https://data.mendeley.com/datasets/tywbtsjrjv/1/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/Plant_leaf_diseases_dataset_without_augmentation.zip?dl=1  to  plant_leaf.zip\n",
            "Decompressing into:  plant_leaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r plant_leaf/Plant_leave_diseases_dataset_without_augmentation/Background_without_leaves -R"
      ],
      "metadata": {
        "id": "EEJxc43iKr2m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"plant_leaf/Plant_leave_diseases_dataset_without_augmentation/\"\n",
        "\n",
        "label_of_classes = os.listdir(data_dir)\n",
        "print(\"Classes Lables:\", label_of_classes)\n",
        "\n",
        "number_of_classes = len(label_of_classes)\n",
        "print(\"Number of Classes:\", number_of_classes)\n",
        "\n",
        "train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(\n",
        "    seed=7,\n",
        "    root_dir=data_dir,\n",
        "    lab=True,\n",
        "    verbose=Verbose,\n",
        "    bipolar=False,\n",
        "    base_model_name='plant_leaf',\n",
        "    training_size=0.6,\n",
        "    validation_size=0.2,\n",
        "    test_size=0.2,\n",
        "    target_size=(input_shape[0],input_shape[1]),\n",
        "    has_training=True,\n",
        "    has_validation=True,\n",
        "    has_testing=True,\n",
        "    smart_resize=True\n",
        ")\n",
        "\n",
        "print(train_x.shape,val_x.shape,test_x.shape)\n",
        "print(train_y.shape,val_y.shape,test_y.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:07:02.146444Z",
          "iopub.execute_input": "2024-01-20T11:07:02.146807Z",
          "iopub.status.idle": "2024-01-20T11:08:53.108535Z",
          "shell.execute_reply.started": "2024-01-20T11:07:02.146780Z",
          "shell.execute_reply": "2024-01-20T11:08:53.107512Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV_fWePKJYd2",
        "outputId": "f562ddf4-9f10-4cdd-e52b-88dcfc4b466f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes Lables: ['Potato___healthy', 'Apple___Black_rot', 'Strawberry___healthy', 'Strawberry___Leaf_scorch', 'Corn___Common_rust', 'Corn___healthy', 'Corn___Northern_Leaf_Blight', 'Tomato___Septoria_leaf_spot', 'Tomato___Bacterial_spot', 'Potato___Late_blight', 'Cherry___Powdery_mildew', 'Grape___Esca_(Black_Measles)', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Tomato___Leaf_Mold', 'Pepper,_bell___healthy', 'Grape___Black_rot', 'Tomato___Late_blight', 'Orange___Haunglongbing_(Citrus_greening)', 'Squash___Powdery_mildew', 'Tomato___Target_Spot', 'Pepper,_bell___Bacterial_spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Early_blight', 'Potato___Early_blight', 'Grape___healthy', 'Peach___Bacterial_spot', 'Cherry___healthy', 'Apple___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Blueberry___healthy', 'Peach___healthy', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Apple___Cedar_apple_rust', 'Apple___Apple_scab', 'Soybean___healthy', 'Raspberry___healthy']\n",
            "Number of Classes: 38\n",
            "Loading  38  classes.\n",
            "smart resize is enabled.\n",
            "loading train images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting Model for L_ratio and AB_ratio"
      ],
      "metadata": {
        "id": "0U4CV9yDJYd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for l_ratio in [0.25]:\n",
        "\n",
        "        basefilename = 'Apple13-2Path5-LAB-m4-' + str(l_ratio)\n",
        "        print('Running: '+basefilename)\n",
        "\n",
        "        model = two_path5_inception_v3(\n",
        "            include_top=True,\n",
        "            weights=None,\n",
        "            input_tensor=None,\n",
        "            input_shape=input_shape,\n",
        "            two_paths=True,\n",
        "            pooling='max',\n",
        "            classes=number_of_classes,\n",
        "            l_ratio=l_ratio,\n",
        "            ab_ratio=(1.0-l_ratio),\n",
        "            max_mix_idx=4\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        best_result_file_name = basefilename+'-best_result.hdf5'\n",
        "\n",
        "        save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=best_result_file_name,\n",
        "            monitor=monitor,\n",
        "            verbose=True,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=False,\n",
        "            mode='max',\n",
        "            save_freq='epoch'\n",
        "        )\n",
        "\n",
        "        history = model.fit(\n",
        "            train_x,\n",
        "            train_y,\n",
        "            epochs=120,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(val_x,val_y),\n",
        "            callbacks=[save_best],\n",
        "            class_weight=classweight,\n",
        "            workers=multiprocessing.cpu_count()\n",
        "        )\n",
        "\n",
        "        history_filename = basefilename +'-History.png'\n",
        "        plot_history(history_filename)\n",
        "\n",
        "        print('Testing Last Model: '+basefilename)\n",
        "\n",
        "        evaluated = model.evaluate(test_x,test_y)\n",
        "\n",
        "        for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "            print(name,metric)\n",
        "\n",
        "        # print('Best Model Results: '+basefilename)\n",
        "\n",
        "        # model = tf.keras.models.load_model(\n",
        "        #     best_result_file_name,\n",
        "        #     custom_objects={'CopyChannels': cai.layers.CopyChannels}\n",
        "        # )\n",
        "\n",
        "        evaluated = model.evaluate(test_x,test_y)\n",
        "\n",
        "        # cai.models.save_model(model, basefilename)\n",
        "\n",
        "        # for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "        #     print(name,metric)\n",
        "\n",
        "        print('Finished: '+basefilename)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T07:14:25.964973Z",
          "iopub.execute_input": "2024-01-20T07:14:25.965936Z",
          "iopub.status.idle": "2024-01-20T09:00:42.581467Z",
          "shell.execute_reply.started": "2024-01-20T07:14:25.965896Z",
          "shell.execute_reply": "2024-01-20T09:00:42.580517Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "uaoIBIfBJYd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calcutale F1 and other metrics"
      ],
      "metadata": {
        "id": "JKkHG4_nJYd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for l_ratio in [0.25]:\n",
        "\n",
        "    basefilename = 'Apple13-2Path5-LAB-m4-' + str(l_ratio)\n",
        "\n",
        "    best_result_file_name = basefilename+'-best_result.hdf5'\n",
        "\n",
        "    print('Best Model Results: '+basefilename)\n",
        "\n",
        "    model = tf.keras.models.load_model(\n",
        "        best_result_file_name,\n",
        "        custom_objects={'CopyChannels': cai.layers.CopyChannels}\n",
        "    )\n",
        "\n",
        "    pred_y = model.predict(test_x)\n",
        "    #         print(\"Predicted Shape:\", pred_y.shape)\n",
        "    pred_classes_y = np.array(list(np.argmax(pred_y, axis=1)))\n",
        "    test_classes_y = np.array(list(np.argmax(test_y, axis=1)))\n",
        "    #         print(\"Pred classes shape:\",pred_classes_y.shape)\n",
        "    #         print(\"Test classes shape:\",test_classes_y.shape)\n",
        "    report = classification_report(test_classes_y, pred_classes_y, digits=4)\n",
        "    print(report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:09:31.535794Z",
          "iopub.execute_input": "2024-01-20T11:09:31.536713Z",
          "iopub.status.idle": "2024-01-20T11:09:56.476082Z",
          "shell.execute_reply.started": "2024-01-20T11:09:31.536665Z",
          "shell.execute_reply": "2024-01-20T11:09:56.475111Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "0sm3aFRZJYd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "cmNn9jRyJYd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for l_ratio in [0.25]:\n",
        "\n",
        "    basefilename = 'Apple13-2Path5-LAB-m4-' + str(l_ratio)\n",
        "\n",
        "    best_result_file_name = basefilename+'-best_result.hdf5'\n",
        "\n",
        "    print('Best Model Results: '+basefilename)\n",
        "    model = tf.keras.models.load_model(\n",
        "        best_result_file_name,\n",
        "        custom_objects={'CopyChannels': cai.layers.CopyChannels}\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_prob = model.predict(test_x)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    # Create the confusion matrix\n",
        "    cm = confusion_matrix(np.argmax(test_y, axis=1), y_pred)\n",
        "\n",
        "    # Visualize the confusion matrix using seaborn\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=label_of_classes, yticklabels=label_of_classes)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    figfilename = basefilename+'-CF.png'\n",
        "    plt.savefig(figfilename, bbox_inches='tight')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-20T11:14:15.571470Z",
          "iopub.execute_input": "2024-01-20T11:14:15.571930Z",
          "iopub.status.idle": "2024-01-20T11:14:42.208607Z",
          "shell.execute_reply.started": "2024-01-20T11:14:15.571894Z",
          "shell.execute_reply": "2024-01-20T11:14:42.207633Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "egHvxgf8JYeA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}